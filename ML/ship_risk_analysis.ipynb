{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Distance  Average_Transit_Days  Number_Of_Travels  \\\n",
      "0  5805.663513             26.379413          27.863568   \n",
      "1  9322.567131             17.044690          36.308224   \n",
      "2  8058.362756             16.163868          25.564987   \n",
      "3  6867.644933             23.526115          41.879096   \n",
      "4  8388.415358             25.976758          17.514580   \n",
      "\n",
      "   Total_Incidents_Count  High_Incidents_Count  Medium_Incidents_Count  \\\n",
      "0                      2                     3                       1   \n",
      "1                      4                     0                       2   \n",
      "2                      5                     1                       2   \n",
      "3                      3                     3                       1   \n",
      "4                      4                     1                       1   \n",
      "\n",
      "   Low_Incidents_Count  High_Last_5Months_Incidents  \\\n",
      "0                    0                            0   \n",
      "1                    1                            1   \n",
      "2                    0                            1   \n",
      "3                    2                            2   \n",
      "4                    3                            1   \n",
      "\n",
      "   Medium_Last_5Months_Incidents  Low_Last_5Months_Incidents  ...  POL_Code  \\\n",
      "0                              3                           2  ...      POL2   \n",
      "1                              1                           1  ...      POL1   \n",
      "2                              0                           1  ...      POL3   \n",
      "3                              1                           0  ...      POL4   \n",
      "4                              0                           3  ...      POL4   \n",
      "\n",
      "  POL_Region POD_Code POD_Region Transshipments_Count  \\\n",
      "0    Region1     POD2    Region3                    2   \n",
      "1    Region1     POD1    Region2                    0   \n",
      "2    Region1     POD1    Region1                    1   \n",
      "3    Region3     POD3    Region1                    0   \n",
      "4    Region1     POD2    Region1                    1   \n",
      "\n",
      "  Average_Transshipment_Days  Transshipment_Risk_Level Carbon_Emissions  \\\n",
      "0                   3.309078                      high       107.342410   \n",
      "1                   4.401758                    medium       122.885401   \n",
      "2                   4.589232                      high       102.616694   \n",
      "3                   2.614629                       low        92.721029   \n",
      "4                   2.860386                       low        46.506429   \n",
      "\n",
      "  Incident_Date    RiskScore  \n",
      "0    2022-08-15     Low Risk  \n",
      "1    2022-07-27     Low Risk  \n",
      "2    2023-02-14    High Risk  \n",
      "3    2023-10-10     Low Risk  \n",
      "4    2023-03-17  Medium Risk  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate a range of dates\n",
    "start_date = datetime(2022, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Generate realistic data\n",
    "data = {\n",
    "    'Distance': np.random.normal(loc=8000, scale=1500, size=num_samples),  # Nautical miles\n",
    "    'Average_Transit_Days': np.random.normal(loc=20, scale=4, size=num_samples),  # Days\n",
    "    'Number_Of_Travels': np.random.normal(loc=30, scale=10, size=num_samples),  # Number of trips\n",
    "    'Total_Incidents_Count': np.random.poisson(lam=4, size=num_samples),  # Count of incidents\n",
    "    'High_Incidents_Count': np.random.poisson(lam=1, size=num_samples),  # High severity incidents\n",
    "    'Medium_Incidents_Count': np.random.poisson(lam=2, size=num_samples),  # Medium severity incidents\n",
    "    'Low_Incidents_Count': np.random.poisson(lam=1, size=num_samples),  # Low severity incidents\n",
    "    'High_Last_5Months_Incidents': np.random.poisson(lam=0.8, size=num_samples),  # Recent high severity incidents\n",
    "    'Medium_Last_5Months_Incidents': np.random.poisson(lam=1.5, size=num_samples),  # Recent medium severity incidents\n",
    "    'Low_Last_5Months_Incidents': np.random.poisson(lam=0.7, size=num_samples),  # Recent low severity incidents\n",
    "    'Average_Vessel_Age': np.random.normal(loc=12, scale=5, size=num_samples),  # Years\n",
    "    'Cargo_Type': np.random.choice(['hazardous', 'non-hazardous'], num_samples),  # Categorical\n",
    "    'Port_Condition': np.random.choice(['well-maintained', 'poor'], num_samples),  # Categorical\n",
    "    'Weather_Condition': np.random.choice(['calm', 'stormy'], num_samples),  # Categorical\n",
    "    'Piracy_Risk': np.random.choice(['high', 'medium', 'low'], num_samples),  # Categorical\n",
    "    'Port_Infrastructure_Quality': np.random.choice(['excellent', 'good', 'fair', 'poor'], num_samples),  # Categorical\n",
    "    'Historical_Incident_Frequency': np.random.normal(loc=0.6, scale=0.2, size=num_samples),  # Incidents per year\n",
    "    'Operational_Disruptions': np.random.choice(['strikes', 'port closures', 'none'], num_samples),  # Categorical\n",
    "    'Navigational_Risks': np.random.choice(['congested areas', 'shallow waters', 'clear'], num_samples),  # Categorical\n",
    "    'Regulatory_Compliance': np.random.choice(['compliant', 'non-compliant'], num_samples),  # Categorical\n",
    "    'Crew_Experience_Level': np.random.normal(loc=10, scale=3, size=num_samples),  # Years\n",
    "    'Ship_Maintenance_Records': np.random.choice(['up-to-date', 'overdue'], num_samples),  # Categorical\n",
    "    'Insurance_Coverage': np.random.choice(['full', 'partial', 'none'], num_samples),  # Categorical\n",
    "    'Cargo_Value': np.random.normal(loc=1500000, scale=300000, size=num_samples),  # USD\n",
    "    'Ship_Type': np.random.choice(['container', 'bulk carrier'], num_samples),  # Categorical\n",
    "    'Route_Duration': np.random.normal(loc=25, scale=5, size=num_samples),  # Days\n",
    "    'Incident_Severity': np.random.choice(['minor', 'major', 'critical'], num_samples),  # Categorical\n",
    "    'Previous_Safety_Awards': np.random.choice(['yes', 'no'], num_samples),  # Categorical\n",
    "    'Training_Programs': np.random.choice(['regular', 'irregular'], num_samples),  # Categorical\n",
    "    'Emergency_Response_Plans': np.random.choice(['in place', 'not in place'], num_samples),  # Categorical\n",
    "    \n",
    "    # New features\n",
    "    'POL_Code': np.random.choice(['POL1', 'POL2', 'POL3', 'POL4'], num_samples),  # Categorical\n",
    "    'POL_Region': np.random.choice(['Region1', 'Region2', 'Region3'], num_samples),  # Categorical\n",
    "    'POD_Code': np.random.choice(['POD1', 'POD2', 'POD3', 'POD4'], num_samples),  # Categorical\n",
    "    'POD_Region': np.random.choice(['Region1', 'Region2', 'Region3'], num_samples),  # Categorical\n",
    "    'Transshipments_Count': np.random.poisson(lam=1.5, size=num_samples),  # Number of transshipments\n",
    "    'Average_Transshipment_Days': np.random.normal(loc=4, scale=1, size=num_samples),  # Days\n",
    "    'Transshipment_Risk_Level': np.random.choice(['high', 'medium', 'low'], num_samples),  # Categorical\n",
    "    'Carbon_Emissions': np.random.normal(loc=100, scale=25, size=num_samples),  # Metric tons\n",
    "\n",
    "    # Generate incident dates\n",
    "    'Incident_Date': [random.choice(date_range).strftime('%Y-%m-%d') for _ in range(num_samples)]  # Random dates\n",
    "}\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding the RiskScore target variable with realistic proportions\n",
    "df['RiskScore'] = np.random.choice(['Low Risk', 'Medium Risk', 'High Risk'], num_samples, p=[0.5, 0.3, 0.2])\n",
    "\n",
    "# Save the DataFrame to a CSV file if needed\n",
    "df.to_csv('realistic_mock_shipping_data_with_dates.csv', index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RiskScore RiskScore_Category\n",
      "0   0.524120                   \n",
      "1  -0.842819                   \n",
      "2  -0.241838                   \n",
      "3   0.243107                   \n",
      "4  -0.769997                   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Sample DataFrame\n",
    "num_samples = 1000\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generating mock data\n",
    "df = pd.DataFrame({\n",
    "    'Distance': np.random.normal(loc=500, scale=100, size=num_samples),\n",
    "    'Average_Transit_Days': np.random.normal(loc=10, scale=2, size=num_samples),\n",
    "    'Number_Of_Travels': np.random.randint(1, 50, size=num_samples),\n",
    "    'Total_Incidents_Count': np.random.poisson(lam=5, size=num_samples),\n",
    "    'Carbon_Emissions': np.random.normal(loc=100, scale=20, size=num_samples),\n",
    "    'Cargo_Value': np.random.normal(loc=1000000, scale=200000, size=num_samples),\n",
    "    'Route_Duration': np.random.normal(loc=15, scale=5, size=num_samples),\n",
    "    'Incident_Date': pd.date_range(start='2023-01-01', periods=num_samples, freq='D'),\n",
    "    'Previous_Safety_Awards': np.random.choice(['yes', 'no'], num_samples),\n",
    "    'Training_Programs': np.random.choice(['regular', 'irregular'], num_samples),\n",
    "    'Incident_Severity': np.random.choice(['minor', 'major', 'critical'], num_samples)\n",
    "})\n",
    "\n",
    "# Convert Incident_Date to datetime\n",
    "df['Incident_Date'] = pd.to_datetime(df['Incident_Date'])\n",
    "\n",
    "# Calculate recent incidents (e.g., incidents in the last 10 days)\n",
    "today = datetime.now()\n",
    "df['Days_Since_Incident'] = (today - df['Incident_Date']).dt.days\n",
    "df['Recent_Incidents'] = df['Days_Since_Incident'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "\n",
    "# Simulating POL and POD codes\n",
    "df['POL_Code'] = np.random.choice(['POL1', 'POL2', 'POL3'], num_samples)\n",
    "df['POD_Code'] = np.random.choice(['POD1', 'POD2', 'POD3'], num_samples)\n",
    "\n",
    "# Aggregate recent incidents\n",
    "recent_incidents_agg = df.groupby(['POL_Code', 'POD_Code', 'Route_Duration'])['Recent_Incidents'].sum().reset_index()\n",
    "recent_incidents_agg.rename(columns={'Recent_Incidents': 'Total_Recent_Incidents'}, inplace=True)\n",
    "df = df.merge(recent_incidents_agg, on=['POL_Code', 'POD_Code', 'Route_Duration'], how='left')\n",
    "\n",
    "# Normalize continuous features\n",
    "for feature in ['Distance', 'Average_Transit_Days', 'Number_Of_Travels', 'Total_Incidents_Count', 'Carbon_Emissions', 'Cargo_Value', 'Route_Duration', 'Total_Recent_Incidents']:\n",
    "    df[feature] = (df[feature] - df[feature].mean()) / df[feature].std()\n",
    "\n",
    "# Encode categorical features\n",
    "df = pd.get_dummies(df, columns=['Previous_Safety_Awards', 'Training_Programs', 'Incident_Severity'])\n",
    "\n",
    "# Define weights (adjust these based on your requirements)\n",
    "weights = {\n",
    "    'Total_Incidents_Count': 0.25,\n",
    "    'Carbon_Emissions': 0.15,\n",
    "    'Number_Of_Travels': 0.1,\n",
    "    'Average_Transit_Days': 0.1,\n",
    "    'Total_Recent_Incidents': 0.15,\n",
    "    'Cargo_Value': 0.1,\n",
    "    'Previous_Safety_Awards_yes': 0.05,\n",
    "    'Training_Programs_regular': 0.05,\n",
    "    'Incident_Severity_minor': 0.05,\n",
    "    'Incident_Severity_major': 0.1\n",
    "}\n",
    "\n",
    "# Calculate RiskScore based on weighted sum\n",
    "df['RiskScore'] = (\n",
    "    df['Total_Incidents_Count'] * weights['Total_Incidents_Count'] +\n",
    "    df['Carbon_Emissions'] * weights['Carbon_Emissions'] +\n",
    "    df['Number_Of_Travels'] * weights['Number_Of_Travels'] +\n",
    "    df['Average_Transit_Days'] * weights['Average_Transit_Days'] +\n",
    "    df['Total_Recent_Incidents'] * weights['Total_Recent_Incidents'] +\n",
    "    df['Cargo_Value'] * weights['Cargo_Value'] +\n",
    "    df['Previous_Safety_Awards_yes'] * weights['Previous_Safety_Awards_yes'] +\n",
    "    df['Training_Programs_regular'] * weights['Training_Programs_regular'] +\n",
    "    df['Incident_Severity_minor'] * weights['Incident_Severity_minor'] +\n",
    "    df['Incident_Severity_major'] * weights['Incident_Severity_major']\n",
    ")\n",
    "\n",
    "# Convert RiskScore to categories (optional)\n",
    "bins = [-np.inf, -1, 0.5, 1, np.inf]\n",
    "labels = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "#df['RiskScore_Category'] = pd.cut(df['RiskScore'], bins=bins, labels=labels)\n",
    "df['RiskScore_Category'] = ''\n",
    "\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('updated_shipping_data_with_risks.csv', index=False)\n",
    "\n",
    "print(df[['RiskScore', 'RiskScore_Category']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RouteID POL_Code POD_Code  RiskScore RiskScore_Category\n",
      "0        1     POL1     POD2   0.723118          High Risk\n",
      "1        2     POL2     POD2   0.557970        Medium Risk\n",
      "2        3     POL1     POD2   0.736983          High Risk\n",
      "3        4     POL2     POD2   0.592353        Medium Risk\n",
      "4        5     POL2     POD1   0.829720          High Risk\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate mock data with RouteID, POL, and POD\n",
    "df = pd.DataFrame({\n",
    "    'RouteID': np.arange(1, num_samples + 1),  # Sequential RouteID\n",
    "    'POL_Code': np.random.choice(['POL1', 'POL2', 'POL3'], num_samples),\n",
    "    'POD_Code': np.random.choice(['POD1', 'POD2', 'POD3'], num_samples),\n",
    "    'Distance': np.random.normal(loc=500, scale=100, size=num_samples),\n",
    "    'Average_Transit_Days': np.random.normal(loc=10, scale=2, size=num_samples),\n",
    "    'Number_Of_Travels': np.random.randint(1, 50, size=num_samples),\n",
    "    'Total_Incidents_Count': np.random.poisson(lam=5, size=num_samples),\n",
    "    'Carbon_Emissions': np.random.normal(loc=100, scale=20, size=num_samples),\n",
    "    'Cargo_Value': np.random.normal(loc=1500000, scale=300000, size=num_samples),\n",
    "    'Route_Duration': np.random.normal(loc=25, scale=5, size=num_samples),\n",
    "    'Incident_Date': [datetime.now() - timedelta(days=np.random.randint(0, 365)) for _ in range(num_samples)],\n",
    "    'Previous_Safety_Awards': np.random.choice(['yes', 'no'], num_samples),\n",
    "    'Training_Programs': np.random.choice(['regular', 'irregular'], num_samples),\n",
    "    'Incident_Severity': np.random.choice(['minor', 'major', 'critical'], num_samples),\n",
    "    'Average_Vessel_Age': np.random.normal(loc=12, scale=5, size=num_samples),\n",
    "    'Cargo_Type': np.random.choice(['hazardous', 'non-hazardous'], num_samples),\n",
    "    'Navigational_Risks': np.random.choice(['congested areas', 'shallow waters', 'clear'], num_samples),\n",
    "    'Regulatory_Compliance': np.random.choice(['compliant', 'non-compliant'], num_samples),\n",
    "    'Crew_Experience_Level': np.random.normal(loc=10, scale=3, size=num_samples),\n",
    "    'Ship_Maintenance_Records': np.random.choice(['up-to-date', 'overdue'], num_samples),\n",
    "    'Insurance_Coverage': np.random.choice(['full', 'partial', 'none'], num_samples),\n",
    "    'Ship_Type': np.random.choice(['container', 'bulk carrier'], num_samples),\n",
    "    'Emergency_Response_Plans': np.random.choice(['in place', 'not in place'], num_samples)\n",
    "})\n",
    "\n",
    "# Convert Incident_Date to datetime\n",
    "df['Incident_Date'] = pd.to_datetime(df['Incident_Date'])\n",
    "\n",
    "# Calculate recent incidents (e.g., incidents in the last 10 days)\n",
    "today = datetime.now()\n",
    "df['Days_Since_Incident'] = (today - df['Incident_Date']).dt.days\n",
    "df['Recent_Incidents'] = df['Days_Since_Incident'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "\n",
    "# Aggregate recent incidents\n",
    "recent_incidents_agg = df.groupby(['POL_Code', 'POD_Code', 'Route_Duration'])['Recent_Incidents'].sum().reset_index()\n",
    "recent_incidents_agg.rename(columns={'Recent_Incidents': 'Total_Recent_Incidents'}, inplace=True)\n",
    "df = df.merge(recent_incidents_agg, on=['POL_Code', 'POD_Code', 'Route_Duration'], how='left')\n",
    "\n",
    "# Normalize continuous features using Min-Max Scaling\n",
    "features = ['Distance', 'Average_Transit_Days', 'Number_Of_Travels', 'Total_Incidents_Count', \n",
    "             'Carbon_Emissions', 'Cargo_Value', 'Route_Duration', 'Total_Recent_Incidents',\n",
    "             'Average_Vessel_Age', 'Crew_Experience_Level']\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Encode categorical features\n",
    "df = pd.get_dummies(df, columns=['Previous_Safety_Awards', 'Training_Programs', 'Incident_Severity',\n",
    "                                 'Cargo_Type', 'Navigational_Risks', 'Regulatory_Compliance',\n",
    "                                 'Ship_Maintenance_Records', 'Insurance_Coverage', 'Ship_Type',\n",
    "                                 'Emergency_Response_Plans'])\n",
    "\n",
    "# Define weights for RiskScore calculation\n",
    "weights = {\n",
    "    'Total_Incidents_Count': 0.2,\n",
    "    'Carbon_Emissions': 0.1,\n",
    "    'Number_Of_Travels': 0.1,\n",
    "    'Average_Transit_Days': 0.1,\n",
    "    'Total_Recent_Incidents': 0.1,\n",
    "    'Cargo_Value': 0.1,\n",
    "    'Average_Vessel_Age': 0.05,\n",
    "    'Crew_Experience_Level': 0.05,\n",
    "    'Cargo_Type_hazardous': 0.05,\n",
    "    'Navigational_Risks_congested areas': 0.05,\n",
    "    'Regulatory_Compliance_non-compliant': 0.05,\n",
    "    'Ship_Maintenance_Records_overdue': 0.05,\n",
    "    'Insurance_Coverage_partial': 0.05,\n",
    "    'Ship_Type_bulk carrier': 0.05,\n",
    "    'Emergency_Response_Plans_not in place': 0.05\n",
    "}\n",
    "\n",
    "# Calculate RiskScore based on weighted sum\n",
    "df['RiskScore'] = (\n",
    "    df['Total_Incidents_Count'] * weights['Total_Incidents_Count'] +\n",
    "    df['Carbon_Emissions'] * weights['Carbon_Emissions'] +\n",
    "    df['Number_Of_Travels'] * weights['Number_Of_Travels'] +\n",
    "    df['Average_Transit_Days'] * weights['Average_Transit_Days'] +\n",
    "    df['Total_Recent_Incidents'] * weights['Total_Recent_Incidents'] +\n",
    "    df['Cargo_Value'] * weights['Cargo_Value'] +\n",
    "    df['Average_Vessel_Age'] * weights['Average_Vessel_Age'] +\n",
    "    df['Crew_Experience_Level'] * weights['Crew_Experience_Level'] +\n",
    "    df['Cargo_Type_hazardous'] * weights['Cargo_Type_hazardous'] +\n",
    "    df['Navigational_Risks_congested areas'] * weights['Navigational_Risks_congested areas'] +\n",
    "    df['Regulatory_Compliance_non-compliant'] * weights['Regulatory_Compliance_non-compliant'] +\n",
    "    df['Ship_Maintenance_Records_overdue'] * weights['Ship_Maintenance_Records_overdue'] +\n",
    "    df['Insurance_Coverage_partial'] * weights['Insurance_Coverage_partial'] +\n",
    "    df['Ship_Type_bulk carrier'] * weights['Ship_Type_bulk carrier'] +\n",
    "    df['Emergency_Response_Plans_not in place'] * weights['Emergency_Response_Plans_not in place']\n",
    ")\n",
    "\n",
    "# Normalize RiskScore to [0, 1] range\n",
    "df['RiskScore'] = (df['RiskScore'] - df['RiskScore'].min()) / (df['RiskScore'].max() - df['RiskScore'].min())\n",
    "\n",
    "# Define bins and labels for RiskScore categories\n",
    "bins = [0, 0.33, 0.66, 1]\n",
    "labels = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "\n",
    "# Convert RiskScore to categories\n",
    "df['RiskScore_Category'] = pd.cut(df['RiskScore'], bins=bins, labels=labels)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('enhanced_shipping_data_with_route_and_risks.csv', index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RouteID</th>\n",
       "      <th>POL_Code</th>\n",
       "      <th>POD_Code</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Average_Transit_Days</th>\n",
       "      <th>Number_Of_Travels</th>\n",
       "      <th>Total_Incidents_Count</th>\n",
       "      <th>Carbon_Emissions</th>\n",
       "      <th>Cargo_Value</th>\n",
       "      <th>Route_Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Ship_Maintenance_Records_up-to-date</th>\n",
       "      <th>Insurance_Coverage_full</th>\n",
       "      <th>Insurance_Coverage_none</th>\n",
       "      <th>Insurance_Coverage_partial</th>\n",
       "      <th>Ship_Type_bulk carrier</th>\n",
       "      <th>Ship_Type_container</th>\n",
       "      <th>Emergency_Response_Plans_in place</th>\n",
       "      <th>Emergency_Response_Plans_not in place</th>\n",
       "      <th>RiskScore</th>\n",
       "      <th>RiskScore_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POL1</td>\n",
       "      <td>POD2</td>\n",
       "      <td>989</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>92.070577</td>\n",
       "      <td>1.566985e+06</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538121</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POL2</td>\n",
       "      <td>POD2</td>\n",
       "      <td>641</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>113.040586</td>\n",
       "      <td>1.689671e+06</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POL1</td>\n",
       "      <td>POD2</td>\n",
       "      <td>780</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>110.204250</td>\n",
       "      <td>1.766207e+06</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.640961</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POL2</td>\n",
       "      <td>POD2</td>\n",
       "      <td>992</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>88.251958</td>\n",
       "      <td>1.621702e+06</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.566359</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POL2</td>\n",
       "      <td>POD1</td>\n",
       "      <td>542</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>89.050140</td>\n",
       "      <td>1.225656e+06</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RouteID POL_Code POD_Code  Distance  Average_Transit_Days  \\\n",
       "0        1     POL1     POD2       989                     9   \n",
       "1        2     POL2     POD2       641                    17   \n",
       "2        3     POL1     POD2       780                    13   \n",
       "3        4     POL2     POD2       992                    10   \n",
       "4        5     POL2     POD1       542                     7   \n",
       "\n",
       "   Number_Of_Travels  Total_Incidents_Count  Carbon_Emissions   Cargo_Value  \\\n",
       "0                 27                      4         92.070577  1.566985e+06   \n",
       "1                 13                      2        113.040586  1.689671e+06   \n",
       "2                 16                      9        110.204250  1.766207e+06   \n",
       "3                 20                      5         88.251958  1.621702e+06   \n",
       "4                 19                      5         89.050140  1.225656e+06   \n",
       "\n",
       "   Route_Duration  ... Ship_Maintenance_Records_up-to-date  \\\n",
       "0              20  ...                               False   \n",
       "1              33  ...                                True   \n",
       "2              16  ...                               False   \n",
       "3              14  ...                               False   \n",
       "4              30  ...                               False   \n",
       "\n",
       "   Insurance_Coverage_full  Insurance_Coverage_none  \\\n",
       "0                    False                     True   \n",
       "1                    False                     True   \n",
       "2                     True                    False   \n",
       "3                    False                     True   \n",
       "4                     True                    False   \n",
       "\n",
       "   Insurance_Coverage_partial  Ship_Type_bulk carrier  Ship_Type_container  \\\n",
       "0                       False                    True                False   \n",
       "1                       False                    True                False   \n",
       "2                       False                    True                False   \n",
       "3                       False                   False                 True   \n",
       "4                       False                   False                 True   \n",
       "\n",
       "   Emergency_Response_Plans_in place  Emergency_Response_Plans_not in place  \\\n",
       "0                              False                                   True   \n",
       "1                               True                                  False   \n",
       "2                               True                                  False   \n",
       "3                               True                                  False   \n",
       "4                              False                                   True   \n",
       "\n",
       "   RiskScore  RiskScore_Category  \n",
       "0   0.538121         Medium Risk  \n",
       "1   0.601449         Medium Risk  \n",
       "2   0.640961         Medium Risk  \n",
       "3   0.566359         Medium Risk  \n",
       "4   0.361939         Medium Risk  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate mock data with RouteID, POL, and POD\n",
    "df = pd.DataFrame({\n",
    "    'RouteID': np.arange(1, num_samples + 1),  # Sequential RouteID\n",
    "    'POL_Code': np.random.choice(['POL1', 'POL2', 'POL3'], num_samples),\n",
    "    'POD_Code': np.random.choice(['POD1', 'POD2', 'POD3'], num_samples),\n",
    "    'Distance': np.random.randint(200, 1000, size=num_samples),  # Integer values for Distance\n",
    "    'Average_Transit_Days': np.random.randint(5, 20, size=num_samples),  # Integer values for Average_Transit_Days\n",
    "    'Number_Of_Travels': np.random.randint(1, 50, size=num_samples),\n",
    "    'Total_Incidents_Count': np.random.poisson(lam=5, size=num_samples),\n",
    "    'Carbon_Emissions': np.random.normal(loc=100, scale=20, size=num_samples),\n",
    "    'Cargo_Value': np.random.normal(loc=1500000, scale=300000, size=num_samples),\n",
    "    'Route_Duration': np.random.randint(10, 40, size=num_samples),  # Integer values for Route_Duration\n",
    "    'Incident_Date': [datetime.now() - timedelta(days=np.random.randint(0, 365)) for _ in range(num_samples)],\n",
    "    'Previous_Safety_Awards': np.random.choice(['yes', 'no'], num_samples),\n",
    "    'Training_Programs': np.random.choice(['regular', 'irregular'], num_samples),\n",
    "    'Incident_Severity': np.random.choice(['minor', 'major', 'critical'], num_samples),\n",
    "    'Average_Vessel_Age': np.random.normal(loc=12, scale=5, size=num_samples),\n",
    "    'Cargo_Type': np.random.choice(['hazardous', 'non-hazardous'], num_samples),\n",
    "    'Navigational_Risks': np.random.choice(['congested areas', 'shallow waters', 'clear'], num_samples),\n",
    "    'Regulatory_Compliance': np.random.choice(['compliant', 'non-compliant'], num_samples),\n",
    "    'Crew_Experience_Level': np.random.normal(loc=10, scale=3, size=num_samples),\n",
    "    'Ship_Maintenance_Records': np.random.choice(['up-to-date', 'overdue'], num_samples),\n",
    "    'Insurance_Coverage': np.random.choice(['full', 'partial', 'none'], num_samples),\n",
    "    'Ship_Type': np.random.choice(['container', 'bulk carrier'], num_samples),\n",
    "    'Emergency_Response_Plans': np.random.choice(['in place', 'not in place'], num_samples)\n",
    "})\n",
    "\n",
    "# Convert Incident_Date to datetime\n",
    "df['Incident_Date'] = pd.to_datetime(df['Incident_Date'])\n",
    "\n",
    "# Calculate recent incidents (e.g., incidents in the last 10 days)\n",
    "today = datetime.now()\n",
    "df['Days_Since_Incident'] = (today - df['Incident_Date']).dt.days\n",
    "df['Recent_Incidents'] = df['Days_Since_Incident'].apply(lambda x: 1 if x <= 10 else 0)\n",
    "\n",
    "# Aggregate recent incidents\n",
    "recent_incidents_agg = df.groupby(['POL_Code', 'POD_Code', 'Route_Duration'])['Recent_Incidents'].sum().reset_index()\n",
    "recent_incidents_agg.rename(columns={'Recent_Incidents': 'Total_Recent_Incidents'}, inplace=True)\n",
    "df = df.merge(recent_incidents_agg, on=['POL_Code', 'POD_Code', 'Route_Duration'], how='left')\n",
    "\n",
    "# Normalize continuous features using Min-Max Scaling\n",
    "features = ['Distance', 'Average_Transit_Days', 'Number_Of_Travels', 'Total_Incidents_Count', \n",
    "             'Carbon_Emissions', 'Cargo_Value', 'Route_Duration', 'Total_Recent_Incidents',\n",
    "             'Average_Vessel_Age', 'Crew_Experience_Level']\n",
    "#scaler = MinMaxScaler()\n",
    "#df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Encode categorical features\n",
    "df = pd.get_dummies(df, columns=['Previous_Safety_Awards', 'Training_Programs', 'Incident_Severity',\n",
    "                                 'Cargo_Type', 'Navigational_Risks', 'Regulatory_Compliance',\n",
    "                                 'Ship_Maintenance_Records', 'Insurance_Coverage', 'Ship_Type',\n",
    "                                 'Emergency_Response_Plans'])\n",
    "\n",
    "# Define weights for RiskScore calculation\n",
    "weights = {\n",
    "    'Total_Incidents_Count': 0.2,\n",
    "    'Carbon_Emissions': 0.1,\n",
    "    'Number_Of_Travels': 0.1,\n",
    "    'Average_Transit_Days': 0.1,\n",
    "    'Total_Recent_Incidents': 0.1,\n",
    "    'Cargo_Value': 0.1,\n",
    "    'Average_Vessel_Age': 0.05,\n",
    "    'Crew_Experience_Level': 0.05,\n",
    "    'Cargo_Type_hazardous': 0.05,\n",
    "    'Navigational_Risks_congested areas': 0.05,\n",
    "    'Regulatory_Compliance_non-compliant': 0.05,\n",
    "    'Ship_Maintenance_Records_overdue': 0.05,\n",
    "    'Insurance_Coverage_partial': 0.05,\n",
    "    'Ship_Type_bulk carrier': 0.05,\n",
    "    'Emergency_Response_Plans_not in place': 0.05\n",
    "}\n",
    "\n",
    "# Calculate RiskScore based on weighted sum\n",
    "df['RiskScore'] = (\n",
    "    df['Total_Incidents_Count'] * weights['Total_Incidents_Count'] +\n",
    "    df['Carbon_Emissions'] * weights['Carbon_Emissions'] +\n",
    "    df['Number_Of_Travels'] * weights['Number_Of_Travels'] +\n",
    "    df['Average_Transit_Days'] * weights['Average_Transit_Days'] +\n",
    "    df['Total_Recent_Incidents'] * weights['Total_Recent_Incidents'] +\n",
    "    df['Cargo_Value'] * weights['Cargo_Value'] +\n",
    "    df['Average_Vessel_Age'] * weights['Average_Vessel_Age'] +\n",
    "    df['Crew_Experience_Level'] * weights['Crew_Experience_Level'] +\n",
    "    df['Cargo_Type_hazardous'] * weights['Cargo_Type_hazardous'] +\n",
    "    df['Navigational_Risks_congested areas'] * weights['Navigational_Risks_congested areas'] +\n",
    "    df['Regulatory_Compliance_non-compliant'] * weights['Regulatory_Compliance_non-compliant'] +\n",
    "    df['Ship_Maintenance_Records_overdue'] * weights['Ship_Maintenance_Records_overdue'] +\n",
    "    df['Insurance_Coverage_partial'] * weights['Insurance_Coverage_partial'] +\n",
    "    df['Ship_Type_bulk carrier'] * weights['Ship_Type_bulk carrier'] +\n",
    "    df['Emergency_Response_Plans_not in place'] * weights['Emergency_Response_Plans_not in place']\n",
    ")\n",
    "\n",
    "# Normalize RiskScore to [0, 1] range\n",
    "df['RiskScore'] = (df['RiskScore'] - df['RiskScore'].min()) / (df['RiskScore'].max() - df['RiskScore'].min())\n",
    "\n",
    "# Define bins and labels for RiskScore categories\n",
    "bins = [0, 0.33, 0.66, 1]\n",
    "labels = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "\n",
    "# Convert RiskScore to categories\n",
    "df['RiskScore_Category'] = pd.cut(df['RiskScore'], bins=bins, labels=labels)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('enhanced_shipping_data_with_route_and_risks1.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "995    False\n",
       "996     True\n",
       "997     True\n",
       "998     True\n",
       "999     True\n",
       "Name: RiskScore_Category, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RiskScore_Category']=='Medium Risk'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
